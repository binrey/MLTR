{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from dataloading import DataParser\n",
    "from easydict import EasyDict\n",
    "\n",
    "from indicators import ZigZagNew\n",
    "from backtest import MovingWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hold(p):\n",
    "    hold = p if p[-1] - p[0] > 0 else -p\n",
    "    return hold - hold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, feature_size, nh):\n",
    "        self.nh = nh\n",
    "        self.feature_size = feature_size\n",
    "        self.inp_size = self.feature_size + 2        \n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.fc_features_in = nn.Linear(self.feature_size, nh)\n",
    "        self.fc_last_state_in = nn.Linear(2, nh)\n",
    "        self.fc_hid = nn.Linear(nh, nh)\n",
    "        self.fc_out = nn.Linear(nh, 1)\n",
    "\n",
    "        self.batch_norm_hid = nn.BatchNorm1d(nh)\n",
    "        self.batch_norm_out = nn.BatchNorm1d(1)        \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     features, last_pred, last_res = x[:, :-1], x[:, -2:-1], x[:, -1:]\n",
    "    #     last_state_pred = self.tanh(self.tanh(last_res*10)*last_pred*10)\n",
    "    #     return last_state_pred\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features, last_state = x[:, :-2], x[:, -2:]\n",
    "\n",
    "        # last_state = self.relu(self.fc_last_state_in(self.last_state))\n",
    "        # last_state = self.relu(self.fc_hid(last_state))\n",
    "        # last_state = self.fc_out(last_state)\n",
    "\n",
    "        features = self.relu(self.fc_features_in(features))\n",
    "        features = self.batch_norm_hid(features)\n",
    "        # features = self.relu(self.fc_hid(features))\n",
    "        # features = self.batch_norm_hid(features)\n",
    "        # features = self.relu(self.fc_hid(features))\n",
    "        # features = self.batch_norm_hid(features)\n",
    "        # features = self.relu(self.fc_hid(features))\n",
    "        # features = self.batch_norm_hid(features)\n",
    "        features = self.fc_out(features)\n",
    "        \n",
    "        output = self.tanh(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(5, 5)\n",
    "print(model.inp_size)\n",
    "model.eval()\n",
    "model(torch.ones((1, model.inp_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([math.sin(x/2)+x/4 for x in range(30)])# + (np.random.random(L)-0.5)*2\n",
    "dp = p[1:] - p[:-1]\n",
    "hold = compute_hold(p)\n",
    "plt.plot(p, \".-\")\n",
    "plt.plot(hold)\n",
    "plt.plot(dp)\n",
    "\n",
    "fsize = 3\n",
    "features = []\n",
    "for i in range(p.shape[0]):\n",
    "    if i < fsize-1:\n",
    "        features.append(np.zeros(fsize))\n",
    "    else:\n",
    "        features.append(p[i-fsize+1:i+1] - p[i])\n",
    "\n",
    "features = torch.from_numpy(np.array(features).astype(np.float32))\n",
    "for i in range(fsize-1, 10):\n",
    "    plt.plot(range(i-fsize+1, i+1), features[i].numpy())\n",
    "plt.grid(\"on\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = EasyDict({\"data_type\": \"metatrader\", \"period\": \"M60\", \"ticker\": \"SBER\"})\n",
    "data_pd, data_np = DataParser(cfg).load()\n",
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsize = 256\n",
    "fsize = 3\n",
    "zz = ZigZagNew(5)\n",
    "mw = MovingWindow(data_np, wsize)\n",
    "last_type = 0\n",
    "p, features = [], []\n",
    "# for t in range(wsize*5-1, data_np.Close.shape[0]):\n",
    "for t in range(1600, data_np.Close.shape[0]): # best - 1500\n",
    "    hist_window = mw(t)[0]\n",
    "    zzx, zzp, zzt = zz.update(hist_window)\n",
    "    zzx -= zzx[0]\n",
    "    zzp -= zzp[-1]\n",
    "    # zzx = 127 - zzx\n",
    "    if zzt[-1] != last_type:\n",
    "        last_type = zzt[-1]\n",
    "        # plt.plot(zzx, zzp)\n",
    "        # plt.plot(hist_window.Low - hist_window.Low[-1])\n",
    "        # plt.plot(hist_window.High - hist_window.High[-1])\n",
    "        \n",
    "        p.append(hist_window.Close[-1])\n",
    "        features.append(np.vstack([zzp[:fsize]]))\n",
    "        # features.append(p[-1])\n",
    "        if len(p) >= 150:\n",
    "            break\n",
    "        \n",
    "features = torch.from_numpy(np.array(features).astype(np.float32))\n",
    "features = features.squeeze()\n",
    "p = torch.from_numpy(np.array(p).astype(np.float32))*10\n",
    "dp = p[1:] - p[:-1]\n",
    "hold = compute_hold(p)\n",
    "print(features.shape, dp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hold)\n",
    "plt.plot(p - p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(fsize-1, 20):\n",
    "    plt.plot(range(i-fsize+1, i+1), features[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reshape((-1, fsize*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(features.shape[1], 24)\n",
    "model.eval()\n",
    "summary(model, (model.inp_size,), device=\"cpu\")\n",
    "\n",
    "# model.fc2.weight = nn.Parameter(torch.tensor([[10.]]))\n",
    "# for param in model.fc2.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# print(model.fc2.weight)\n",
    "# print(model.fc2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.inp_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "def autoregress_sequense(dp, features, epoch=0, output_sequense=False):\n",
    "    outputs, pred_results = torch.zeros(dp.shape[0]), torch.zeros(dp.shape[0])\n",
    "    loss, output, pred_result = 0, torch.zeros((1, 1)), torch.zeros((1, 1))\n",
    "    for i in range(dp.shape[0]):\n",
    "        input = torch.hstack([features[i:i+1], output, pred_result])\n",
    "        output = model(input)\n",
    "        pred_result = dp[i] * output\n",
    "\n",
    "        if output_sequense:\n",
    "            outputs[i] = output\n",
    "            pred_results[i] = pred_result\n",
    "        else:\n",
    "            loss -= pred_result\n",
    "            print(f\"{epoch + 1:03} {i + 1:04}: {loss.item():7.3f} -= {output.item():6.3f} * {dp[i]:6.3f}= {pred_result.item():6.3f}\")            \n",
    "    if output_sequense:\n",
    "        return outputs.detach().numpy(), pred_results.detach().numpy()\n",
    "    else:\n",
    "        return loss, output\n",
    "        \n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss, _ = autoregress_sequense(dp, features, epoch)\n",
    "    loss += hold[-1]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "model.eval()\n",
    "pred_deals, pred_res = torch.zeros(dp.shape[0]), torch.zeros(dp.shape[0])\n",
    "pred_deal_last, pred_res_last = 1*torch.zeros((1, 1)), -torch.zeros((1, 1))\n",
    "# pred_deal_last, pred_res_last = -1*torch.ones((1, 1)), torch.ones((1, 1))\n",
    "\n",
    "pred_deals, pred_res = autoregress_sequense(dp, features, output_sequense=True)\n",
    "\n",
    "plt.plot(p - p[0], linewidth=3)\n",
    "plt.bar(list(range(len(pred_deals))), height=pred_deals, alpha=0.4)\n",
    "plt.plot(np.hstack([np.zeros(1), pred_res.cumsum(0)]))\n",
    "plt.grid(\"on\")\n",
    "plt.tight_layout()\n",
    "plt.grid(\"on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold[-1], pred_res.sum(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
