{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [1, 1]                    --\n",
      "├─ModuleList: 1-5                        --                        (recursive)\n",
      "│    └─Conv2d: 2-1                       [1, 4, 7, 32]             116\n",
      "├─MaxPool2d: 1-2                         [1, 4, 7, 16]             --\n",
      "├─ModuleList: 1-5                        --                        (recursive)\n",
      "│    └─Conv2d: 2-2                       [1, 8, 7, 16]             904\n",
      "├─MaxPool2d: 1-4                         [1, 8, 7, 8]              --\n",
      "├─ModuleList: 1-5                        --                        (recursive)\n",
      "│    └─Conv2d: 2-3                       [1, 16, 7, 8]             3,600\n",
      "├─MaxPool2d: 1-6                         [1, 16, 7, 4]             --\n",
      "├─Conv2d: 1-7                            [1, 32, 1, 1]             14,368\n",
      "├─Linear: 1-8                            [1, 1]                    33\n",
      "==========================================================================================\n",
      "Total params: 19,021\n",
      "Trainable params: 19,021\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.34\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.10\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# import timm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "# model = timm.create_model('resnet18', in_chans=1, num_classes=1).float().to(\"mps\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nf, nl):\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        self.nl = nl\n",
    "        self.convs = nn.ModuleList() \n",
    "        n = (1, 4)\n",
    "        for i in range(self.nl):\n",
    "            self.convs.append(nn.Conv2d(n[0], n[1], (self.nf, 4), padding=\"same\"))\n",
    "            n = (n[1], n[1]*2)\n",
    "        self.conv_valid = nn.Conv2d(n[0], n[1], (self.nf, 4), padding=\"valid\")\n",
    "        self.pool = nn.MaxPool2d((1, 2), (1, 2))\n",
    "        self.fc = nn.Linear(n[1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = (1, 4)\n",
    "        for i in range(self.nl):\n",
    "            x = self.convs[i](x)\n",
    "            x = self.pool(F.relu(x))\n",
    "            n = (n[1], n[1]*2)\n",
    "        x = F.relu(self.conv_valid(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.tanh(self.fc(x))\n",
    "        return x\n",
    "model = Net(7, 3)#.to(device)\n",
    "print(summary(model, (1, 1, 7, 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X, y, test_split=0.25):\n",
    "    ids = np.arange(X.shape[0])\n",
    "    # np.random.shuffle(ids)\n",
    "    test_size = int(X.shape[0]*test_split)\n",
    "    ids_test, odates_testset, odates = [], set(), X[:, 0, -2, 0]\n",
    "    while len(ids_test) < test_size:\n",
    "        ix = np.random.randint(0, X.shape[0])\n",
    "        d = odates[ix]\n",
    "        if d not in odates_testset:\n",
    "            ii = ids[odates == d]\n",
    "            ids_test += ii.tolist()\n",
    "            odates_testset.add(d)\n",
    "    ids_train = [ix for ix in ids if ix not in ids_test]   \n",
    "    np.random.shuffle(ids_train) \n",
    "    np.random.shuffle(ids_test) \n",
    "        \n",
    "    # ids_test, ids_train = ids[:test_size], ids[test_size:]\n",
    "    X_train, X_test, y_train, y_test, profs_test = X[ids_train], X[ids_test], y[ids_train], y[ids_test], y[ids_test]\n",
    "    tf_test = X_test[:, 0, -1, 0]\n",
    "    X_train = X_train[:, :, :-2, :]\n",
    "    X_test = X_test[:, :, :-2, :]\n",
    "    \n",
    "    y_train = np.tanh(y_train)\n",
    "    y_test = np.tanh(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, profs_test, tf_test\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.img_labels = y\n",
    "        self.imgs = X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.imgs[idx]\n",
    "        label = self.img_labels[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization/btest000.pickle\n",
      "optimization/btest001.pickle\n",
      "optimization/btest002.pickle\n",
      "optimization/btest003.pickle\n",
      "optimization/btest004.pickle\n",
      "optimization/btest005.pickle\n",
      "optimization/btest006.pickle\n",
      "optimization/btest007.pickle\n",
      "optimization/btest008.pickle\n",
      "optimization/btest009.pickle\n",
      "optimization/btest010.pickle\n",
      "optimization/btest011.pickle\n",
      "optimization/btest012.pickle\n",
      "optimization/btest013.pickle\n",
      "optimization/btest014.pickle\n",
      "optimization/btest015.pickle\n",
      "optimization/btest016.pickle\n",
      "optimization/btest017.pickle\n",
      "optimization/btest018.pickle\n",
      "optimization/btest019.pickle\n",
      "optimization/btest020.pickle\n",
      "optimization/btest021.pickle\n",
      "optimization/btest022.pickle\n",
      "optimization/btest023.pickle\n",
      "optimization/btest024.pickle\n",
      "optimization/btest025.pickle\n",
      "optimization/btest026.pickle\n",
      "optimization/btest027.pickle\n",
      "optimization/btest028.pickle\n",
      "optimization/btest029.pickle\n",
      "optimization/btest030.pickle\n",
      "optimization/btest031.pickle\n",
      "optimization/btest032.pickle\n",
      "optimization/btest033.pickle\n",
      "optimization/btest034.pickle\n",
      "optimization/btest035.pickle\n",
      "optimization/btest036.pickle\n",
      "optimization/btest037.pickle\n",
      "optimization/btest038.pickle\n",
      "optimization/btest039.pickle\n",
      "optimization/btest040.pickle\n",
      "optimization/btest041.pickle\n",
      "optimization/btest042.pickle\n",
      "optimization/btest043.pickle\n",
      "optimization/btest044.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "cfgs, btests = [], []\n",
    "for p in sorted(Path(\"optimization\").glob(\"*.pickle\")):\n",
    "    cfg, btest = pickle.load(open(p, \"rb\"))\n",
    "    cfgs.append(cfg)\n",
    "    btests.append(btest)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBER 467\n",
      "ROSN 301\n",
      "LKOH 324\n",
      "GMKN 307\n",
      "GAZP 318\n",
      "SBER 319\n",
      "ROSN 217\n",
      "LKOH 219\n",
      "GMKN 218\n",
      "GAZP 227\n",
      "SBER 256\n",
      "ROSN 189\n",
      "LKOH 175\n",
      "GMKN 173\n",
      "GAZP 181\n",
      "SBER 634\n",
      "ROSN 414\n",
      "LKOH 445\n",
      "GMKN 415\n",
      "GAZP 409\n",
      "SBER 469\n",
      "ROSN 312\n",
      "LKOH 327\n",
      "GMKN 313\n",
      "GAZP 317\n",
      "SBER 406\n",
      "ROSN 271\n",
      "LKOH 278\n",
      "GMKN 261\n",
      "GAZP 275\n",
      "SBER 834\n",
      "ROSN 524\n",
      "LKOH 554\n",
      "GMKN 540\n",
      "GAZP 542\n",
      "SBER 661\n",
      "ROSN 436\n",
      "LKOH 450\n",
      "GMKN 445\n",
      "GAZP 435\n",
      "SBER 577\n",
      "ROSN 390\n",
      "LKOH 409\n",
      "GMKN 370\n",
      "GAZP 388\n",
      "(16902, 1, 9, 8) (16902,)\n"
     ]
    }
   ],
   "source": [
    "from backtest import DataParser, MovingWindow\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import log_evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from indicators import ZigZag\n",
    "\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat), False\n",
    "\n",
    "fsize = 8\n",
    "tfdict = {\"M5\":0, \"M15\":1, \"H1\":2}\n",
    "zz = ZigZag()\n",
    "X, y, poslist = [], [], []\n",
    "for btest in btests:\n",
    "    print(btest.cfg.ticker, end=\" \")\n",
    "    hist_pd, hist = DataParser(btest.cfg).load()\n",
    "    mw = MovingWindow(hist, fsize+2)\n",
    "    print(len(btest.positions))\n",
    "    for pos in btest.positions[2:]:\n",
    "        f, _ = mw(pos.open_indx)\n",
    "        fo = f.Open[:-2]/f.Open[-2]\n",
    "        fc = f.Close[:-2]/f.Open[:-2]\n",
    "        fh = f.High[:-2]/f.Open[:-2]\n",
    "        fl = f.Low[:-2]/f.Open[:-2]\n",
    "        fv = f.Volume[:-2]/f.Volume[-2] if f.Volume[-2] != 0 else np.ones_like(f.Volume[:-2])\n",
    "        odate = pd.to_datetime(pos.open_date)\n",
    "        odate = odate.year*10000 + odate.month*100 + odate.day\n",
    "        if pos.dir > 0:\n",
    "            x = np.vstack([fc, fo, fl, fh])\n",
    "        else:\n",
    "            x = np.vstack([2-fc, 2-fo, 2-fl, 2-fh])\n",
    "        x = x*100 - 100\n",
    "        # print(x.flatten())\n",
    "        x = np.vstack([x, fv])\n",
    "        x = np.vstack([x, np.ones(x.shape[1])*btest.cfg.stops_processor.func.cfg.sl/6+1])\n",
    "        x = np.vstack([x, np.ones(x.shape[1])*btest.cfg.trailing_stop_rate/0.04+1])\n",
    "        x = np.vstack([x, np.ones(x.shape[1])*odate])\n",
    "        x = np.vstack([x, np.ones(x.shape[1])*tfdict[btest.cfg.period]])\n",
    "        X.append([x])\n",
    "        y.append(pos.profit)\n",
    "        poslist.append(pos)\n",
    "        \n",
    "X, y = np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12671, 1, 7, 8) (4231, 1, 7, 8) (4231,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17e08d4e0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1000)\n",
    "X_train, X_test, y_train, y_test, profs_test, tf_test = get_data(X, y)\n",
    "print(X_train.shape, X_test.shape, tf_test.shape)\n",
    "plt.imshow(X_train[0][0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_builder, batch_size):\n",
    "    trainloader = torch.utils.data.DataLoader(CustomImageDataset(X_train, y_train), \n",
    "                                              batch_size=batch_size, \n",
    "                                              shuffle=True)\n",
    "    model = model_builder(7, 1).to(device)\n",
    "    # print(summary(model, (1, 6, 32)))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    for epoch in range(30):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs.float().to(device))\n",
    "            loss = criterion(outputs[:, 0], labels.float().to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        # loss_test = criterion(model(torch.tensor(X_test).float().to(device)), \n",
    "        #                       torch.tensor(y_test).float().to(device))\n",
    "        # print(f\"[{epoch + 1:03d}, {i + 1:5d}] loss train: {running_loss / (i + 1):.3f} | test: {loss_test / (i + 1):.3f}\")\n",
    "        running_loss = 0.0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 profit M5 :   +0.0 ->    +0.0 --\n",
      "000 profit M15:   +0.0 ->    +0.0 --\n",
      "000 profit H1 :+2224.1 -> +2246.9 OK\n",
      "000 mae_train: 0.76 mae_test: 0.78\n",
      "-------------------------------------------------\n",
      "[          nan           nan 2224.08520508]  ->  [          nan           nan 2246.85888672]\n",
      "mae_train: 0.76 mae_test: 0.78 ratio: 1.03\n",
      "av. profit boost: 0.010239572471696306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/hd5pllps0vs0ln9s5xlr768w0000gn/T/ipykernel_37844/1433817688.py:27: RuntimeWarning: Mean of empty slice.\n",
      "  pprofs_mean = pprofits.mean(axis=1, where=pprofits!=0)\n",
      "/Users/andrybin/miniforge3/lib/python3.10/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/var/folders/kw/hd5pllps0vs0ln9s5xlr768w0000gn/T/ipykernel_37844/1433817688.py:28: RuntimeWarning: Mean of empty slice.\n",
      "  gprofs_mean = gprofits.mean(axis=1, where=gprofits!=0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(i)\n\u001b[1;32m      7\u001b[0m X_train, X_test, y_train, y_test, profs_test, tf_test \u001b[38;5;241m=\u001b[39m get_data(X, y)\n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_train):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# p_train = model.predict(X_train)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     p_train \u001b[38;5;241m=\u001b[39m model(torch\u001b[38;5;241m.\u001b[39mtensor(X_train)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[79], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model_builder, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs[:, \u001b[38;5;241m0\u001b[39m], labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[72], line 30\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl):\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs[i](x)\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     n \u001b[38;5;241m=\u001b[39m (n[\u001b[38;5;241m1\u001b[39m], n[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_valid(x))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    167\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, ceil_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[1;32m    168\u001b[0m                         return_indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool2d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nitrers = 10\n",
    "id2tf = {v:k for k, v in tfdict.items()}\n",
    "\n",
    "pprofits, gprofits, metrics = np.zeros((3, nitrers)), np.zeros((3, nitrers)), np.zeros((2, nitrers))\n",
    "for i in range(nitrers):\n",
    "    np.random.seed(i)\n",
    "    X_train, X_test, y_train, y_test, profs_test, tf_test = get_data(X, y)\n",
    "    model = train(Net, 256)\n",
    "    \n",
    "    if len(X_train):\n",
    "        # p_train = model.predict(X_train)\n",
    "        p_train = model(torch.tensor(X_train).float().to(device)).detach().cpu().numpy().squeeze()\n",
    "        # threshold = np.percentile(p_train, 10)\n",
    "        metrics[0, i] = mean_absolute_error(p_train, y_train)\n",
    "    # p_test = model.predict(X_test)\n",
    "    p_test = model(torch.tensor(X_test).float().to(device)).detach().cpu().numpy().squeeze()\n",
    "    metrics[1, i] = mean_absolute_error(p_test, y_test)\n",
    "    \n",
    "    threshold = np.percentile(p_train, 10)\n",
    "    for j in range(3):\n",
    "        ids = tf_test == j\n",
    "        pprofits[j, i] = (profs_test[ids]*(p_test[ids]>threshold)).sum()\n",
    "        gprofits[j, i] = profs_test[ids].sum()\n",
    "        print(f\"{i:03} profit {id2tf[j]:3}:{gprofits[j, i]:+7.1f} -> {pprofits[j, i]:+7.1f} {'OK' if pprofits[j, i] > gprofits[j, i] else '--'}\")\n",
    "    print(f\"{i:03} mae_train: {metrics[0, i]:4.2f} mae_test: {metrics[1, i]:4.2f}\")\n",
    "    \n",
    "    pprofs_mean = pprofits.mean(axis=1, where=pprofits!=0)\n",
    "    gprofs_mean = gprofits.mean(axis=1, where=gprofits!=0)\n",
    "    f1_mean = metrics.mean(axis=1, where=metrics!=0)\n",
    "    pprofs_mean_tot = np.nanmean(pprofs_mean)\n",
    "    gprofs_mean_tot = np.nanmean(gprofs_mean)\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(gprofs_mean, \" -> \", pprofs_mean)\n",
    "    print(f\"mae_train: {f1_mean[0]:4.2f} mae_test: {f1_mean[1]:4.2f} ratio: {f1_mean[1]/f1_mean[0]:4.2f}\")\n",
    "    print(f\"av. profit boost: {(pprofs_mean_tot - gprofs_mean_tot)/abs(gprofs_mean_tot)}\")\n",
    "\n",
    "plt.figure(figsize=(20, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(p_train[:100], \".\")\n",
    "plt.bar(np.arange(100), y_train[:100], width=[1]*100, alpha=0.4)\n",
    "plt.plot([0, 100], [threshold, threshold])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(p_test[:100], \".\")\n",
    "plt.bar(np.arange(100), y_test[:100], width=[1]*100, alpha=0.4)\n",
    "# plt.bar(np.arange(100), profs_test[:100], width=[1]*100, alpha=0.2)\n",
    "plt.plot([0, 100], [threshold, threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_test<threshold).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:6.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m)))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Net' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "print(\" \".join(map(\"{:6.4f}\".format, model.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1112, 3653, 3682, 3682)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum(), (p_test>threshold).sum(), p_test.shape[0], y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "\n",
    "ticker = \"GAZP\"\n",
    "tf = \"H1\"\n",
    "hist_pd, hist = DataParser(\n",
    "    EasyDict(\n",
    "        date_start=\"2008-01-01\",\n",
    "        period=tf,\n",
    "        ticker=ticker,\n",
    "        data_type=\"metatrader\"\n",
    "        )).load()\n",
    "\n",
    "for i in ids_test:\n",
    "    pos = poslist[i]\n",
    "    if pos.ticker == ticker:\n",
    "        prediction = model.predict_proba([X[i, :-1]])[0][1]\n",
    "        if prediction < threshold:\n",
    "            print(pos.ticker, pos.open_date, prediction)\n",
    "            d2 = pd.to_datetime(pos.close_date)\n",
    "            d1 = pd.to_datetime(pos.open_date)\n",
    "            d0 = d1 - pd.DateOffset(days=3)\n",
    "            hist2plot = hist_pd.loc[d0:d2]\n",
    "            fig = mpf.plot(hist2plot, \n",
    "                type='candle', \n",
    "                block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49287947, 0.50712053]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fee188bb3a88b2f91c21b23bf544ec11647f6207f57c38bc925e29c2adb397fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
