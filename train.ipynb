{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from easydict import EasyDict\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from ml import train\n",
    "from dataloading import get_data, build_features, DataParser, MovingWindow\n",
    "from tabulate import tabulate\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_bin_labels(y, dp=0.3):\n",
    "    y = y.astype(np.float32)\n",
    "    d = np.random.uniform(0, dp, sum(y[:, 0]==0))\n",
    "    y[y[:, 0]==0, 0] = d\n",
    "    y[y[:, 1]==1, 1] = 1-d\n",
    "    return y\n",
    "\n",
    "def smooth_prob_labels(y, dp=0.1):\n",
    "    y = y.astype(float)\n",
    "    d = np.random.uniform(-dp, dp, sum(y[:, 0]==0))\n",
    "    y += dp\n",
    "    return y\n",
    "\n",
    "def stohastic_prediction(input_tensor):\n",
    "    pmeans, pstds, ymeans = np.zeros((3, input_tensor.shape[0]))\n",
    "    for i, x in enumerate(input_tensor):\n",
    "        p = model(torch.stack([x]*7)).detach().cpu().numpy()[:, 0]\n",
    "        pmeans[i] = np.median(p)\n",
    "        pstds[i] = p.std()\n",
    "    pmeans = pmeans*(pstds<0.1)\n",
    "    return pmeans, pstds\n",
    "\n",
    "def calc_weights(predicts, th):\n",
    "    p = (predicts > th).astype(np.float32)\n",
    "    return p\n",
    "    #return np.clip((predicts+th)**30, 0, 1)\n",
    "    \n",
    "def calc_weights2(predicts, th):\n",
    "    p = (predicts>th).sum(axis=0)/predicts.shape[0] >= 0.2\n",
    "    #p = np.median(predicts, axis=0) > th\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloading import collect_train_data\n",
    "X, y = collect_train_data(\"./optimization/\", 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"mps\"\n",
    "\n",
    "nitrers = 10\n",
    "test_split_size = 0.2\n",
    "calc_test = True\n",
    "\n",
    "pprofits, gprofits, metrics, table = np.zeros((3, nitrers)), np.zeros((3, nitrers)), np.zeros((2, nitrers)), []\n",
    "for i in range(1):#int(1/test_split_size)):\n",
    "    if i >= 0:\n",
    "        np.random.seed(i)\n",
    "        X_train, X_test, y_train, y_test, profs_train, profs_test, tf_test, _ = get_data(X, y, test_split_size, 4, 5)\n",
    "    X_train = torch.tensor(X_train).float().to(device)\n",
    "    X_test = torch.tensor(X_test).float().to(device)\n",
    "    model = train(X_train, y_train, X_test, y_test, batch_size=512, epochs=10, device=device, calc_test=calc_test)\n",
    "    model.eval()\n",
    "    p_test = model(X_test).detach().cpu().numpy().squeeze()[:, 0]\n",
    "    p_train = model(X_train).detach().cpu().numpy().squeeze()[:, 0]    \n",
    "    y_test = y_test>0\n",
    "    y_train=y_train>0\n",
    "    # p_test, _ = stohastic_prediction(X_test)\n",
    "    # p_train, _ = stohastic_prediction(X_train) \n",
    "    \n",
    "    p_test = np.expand_dims(p_test, 0)\n",
    "    # for m in range(3):\n",
    "    #     np.random.seed(m+100)\n",
    "    #     train_ids = np.random.choice(np.arange(y_train.shape[0]), int(y_train.shape[0]*0.7))\n",
    "    #     model = train(X_train[train_ids], y_train[train_ids], X_test, y_test, batch_size=512, device=device, calc_test=False)\n",
    "    #     model.eval()\n",
    "    #     p_test_ = model(X_test).detach().cpu().numpy().squeeze()[:, 0]\n",
    "    #     p_test = np.vstack([p_test, p_test_])\n",
    "    # p_test = np.median(p_test, 0).squeeze()\n",
    "        \n",
    "    roc_train = roc_auc_score(y_train, p_train.reshape(-1, 1))\n",
    "    roc_test = roc_auc_score(y_test, p_test.reshape(-1, 1))\n",
    "    profsum_best, threshold = -999999, np.percentile(p_train, 20)\n",
    "    for th in np.arange(0., 0.9, 0.025):\n",
    "        profsum = f1_score(y_train[:, 0], p_train>th)\n",
    "        if profsum > profsum_best:\n",
    "            profsum_best = profsum\n",
    "            threshold = th\n",
    "\n",
    "    w_profs_train = calc_weights(p_train, threshold)\n",
    "    \n",
    "    if test_split_size > 0:\n",
    "        w_profs_test = calc_weights(p_test[0], threshold)\n",
    "        for j in range(3):\n",
    "            ids = tf_test == j\n",
    "            pprofits[j, i] = (profs_test[ids]*w_profs_test[ids]).sum()\n",
    "            gprofits[j, i] = profs_test[ids].sum()\n",
    "        \n",
    "        pprofs_sum = np.nansum(pprofits[:, :i+1], 0) \n",
    "        gprofs_sum = np.nansum(gprofits[:, :i+1], 0)\n",
    "        profs_ratio = (pprofs_sum - gprofs_sum)/abs(gprofs_sum)*100\n",
    "        curprof_ratio = (pprofs_sum[-1] - gprofs_sum[-1])/abs(gprofs_sum[-1])*100\n",
    "        model_fails = np.nansum(profs_ratio < 0)/(i+1)\n",
    "        prof_boost_mean = np.nanmean(profs_ratio)\n",
    "        prof_boost_median = np.nanmedian(profs_ratio)\n",
    "        prof_boost_std = np.nanstd(profs_ratio)\n",
    "        if i > 0:\n",
    "            clear_output(wait=True)\n",
    "        table.append([i, roc_train, roc_test, pprofs_sum[-1], gprofs_sum[-1], curprof_ratio, \n",
    "                      prof_boost_mean, prof_boost_median, prof_boost_std, model_fails*100, profsum_best, threshold])\n",
    "        print(tabulate(table, headers=[\"iter\", \"ROC train\", \"ROC test\", \"prof\", \"gprof\", \"pboost\", \"pboost mean\", \"pboost median\", \"pboost std\", \"model_fails, %\", \"f1 best\", \"threshold\"]))\n",
    "        print()\n",
    "        \n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(p_train[:100], \".\")\n",
    "plt.bar(np.arange(100), y_train[:100, 0], width=[1]*100, alpha=0.4)\n",
    "plt.plot([0, 100], [threshold, threshold])\n",
    "if len(p_test):\n",
    "    p_test4show = np.median(p_test, axis=0)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(p_test4show[:100], \".\")\n",
    "    plt.bar(np.arange(100), y_test[:100, 0], width=[1]*100, alpha=0.4)\n",
    "    # plt.bar(np.arange(100), profs_test[:100], width=[1]*100, alpha=0.2)\n",
    "    plt.plot([0, 100], [threshold, threshold])\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(w_profs_train[:100])\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(w_profs_test[:100])\n",
    "    # plt.plot(profs_test[:100]*w_profs_test[:100])\n",
    "    # plt.plot(profs_test[:100], linewidth=3, alpha=0.5)  \n",
    "    \n",
    "    \n",
    "model.set_threshold(threshold)\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from experts import ExpertFormation, PyConfig\n",
    "from backtest import backtest\n",
    "from pathlib import Path\n",
    "from dataloading import get_data, collect_train_data\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from ml import train\n",
    "import matplotlib.pyplot as plt\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")\n",
    "\n",
    "\n",
    "\n",
    "test_split_size = 0.2\n",
    "device = \"mps\"\n",
    "cfg = PyConfig().test()\n",
    "cfg.run_model_device = device\n",
    "\n",
    "for _ in range(5):\n",
    "    legend, last_prof = [], 0\n",
    "    for i in range(int(1/test_split_size)):\n",
    "        X_train, X_test, y_train, y_test, profs_train, profs_test, tf_test, test_dates = get_data(X, y, test_split_size, i, i+1)\n",
    "        X_train = torch.tensor(X_train).float().to(device)\n",
    "        model = train(X_train, y_train, None, None, batch_size=512, epochs=5, device=device, calc_test=False)\n",
    "        model.eval()\n",
    "        X_train = X_train.float().to(device)\n",
    "        p_train = model(X_train).detach().cpu().numpy().squeeze()[:, 0]    \n",
    "        profsum_best, threshold = -999999, np.percentile(p_train, 10)\n",
    "        for th in np.arange(0., 0.9, 0.025):\n",
    "            profsum = f1_score(y_train[:, 0]>0, p_train>th)\n",
    "            if profsum > profsum_best:\n",
    "                profsum_best = profsum\n",
    "                threshold = th\n",
    "        model.set_threshold(threshold)\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        cfg.date_start=f\"{test_dates[0][:4]}-{test_dates[0][4:6]}-{test_dates[0][6:]}\"\n",
    "        cfg.date_end=f\"{test_dates[1][:4]}-{test_dates[1][4:6]}-{test_dates[1][6:]}\"\n",
    "        brok_results = backtest(cfg)\n",
    "        cumsum = brok_results.profits.cumsum()\n",
    "        print(brok_results.profits.sum(), threshold)\n",
    "        plt.plot([pos.close_date for pos in brok_results.positions], cumsum + last_prof)\n",
    "        last_prof += cumsum[-1]\n",
    "        plt.grid(\"on\")\n",
    "        plt.tight_layout()\n",
    "        legend.append(f\"{test_dates[0]}-{test_dates[1]}\")\n",
    "\n",
    "cfg.run_model_device = None\n",
    "cfg.date_start=\"2004-01-01\"\n",
    "cfg.date_end=\"2024-01-01\"\n",
    "brok_results = backtest(cfg)\n",
    "print(brok_results.profits.sum())\n",
    "plt.plot([pos.close_date for pos in brok_results.positions], brok_results.profits.cumsum(), linewidth=3, alpha=0.6)\n",
    "legend.append(\"baseline\")\n",
    "# plt.legend(legend)\n",
    "plt.savefig(\"backtest.png\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ml import Net\n",
    "device = \"cuda\"\n",
    "model = Net(7, 64)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.forward_thresholded(X_test)[:, 0]\n",
    "w_profs_test = calc_weights(p_test[0], threshold)\n",
    "pprofs_test = (profs_test*w_profs_test).sum(0)\n",
    "pprofs_test, profs_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprofs_sum1 = np.nansum(pprofits, 1)\n",
    "gprofs_sum1 = np.nansum(gprofits, 1)\n",
    "pprofs_sum1, gprofs_sum1, (pprofs_sum1-gprofs_sum1)/abs(gprofs_sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(table)[:, 3], \".-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train.mean(), threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ml import Net\n",
    "device = \"cuda\"\n",
    "model = Net(7, 32)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "# model.set_threshold(-6)\n",
    "model.to(device)\n",
    "X_train, X_test, y_train, y_test, profs_train, profs_test, tf_test = get_data(X, y, test_split=1)\n",
    "p_test = model(torch.tensor(X_test).float().to(device)).squeeze()\n",
    "# profs_test.sum(), (profs_test*p_test).sum()\n",
    "p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.named_parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model(torch.tensor(X_test).float().to(device)).squeeze().detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sum(), (p_test>threshold).sum(), p_test.shape[0], y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "\n",
    "ticker = \"BTCUSDT\"\n",
    "tf = \"H1\"\n",
    "hist_pd, hist = DataParser(\n",
    "    EasyDict(\n",
    "        date_start=\"2008-01-01\",\n",
    "        period=tf,\n",
    "        ticker=ticker,\n",
    "        data_type=\"bitfinex\"\n",
    "        )).load()\n",
    "\n",
    "for i in ids_test:\n",
    "    pos = poslist[i]\n",
    "    if pos.ticker == ticker:\n",
    "        prediction = model.predict_proba([X[i, :-1]])[0][1]\n",
    "        if prediction < threshold:\n",
    "            print(pos.ticker, pos.open_date, prediction)\n",
    "            d2 = pd.to_datetime(pos.close_date)\n",
    "            d1 = pd.to_datetime(pos.open_date)\n",
    "            d0 = d1 - pd.DateOffset(days=3)\n",
    "            hist2plot = hist_pd.loc[d0:d2]\n",
    "            fig = mpf.plot(hist2plot, \n",
    "                type='candle', \n",
    "                block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fee188bb3a88b2f91c21b23bf544ec11647f6207f57c38bc925e29c2adb397fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
